import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import RandomOverSampler
import copy
import seaborn as sns
import tensorflow as tf
from sklearn.linear_model import LinearRegression


df = pd.read_csv('SeoulBikeData.csv')
df.head()


# Dropped some columns
df = df.drop(['Date', 'Holiday', 'Seasons'], axis=1)
df.head()


# Changing the column names
columns = ["bike_count", "hour", "temp", "humidity", "wind", "visibility", "dew_pt_temp", "radiation", "rain", "snow", "functional"]
df.columns = columns
df.head()


df['functional'] = (df['functional']=='Yes').astype(int)
df.head()


# Choosing only data having hour as 12
df = df[df['hour']==12]
df = df.drop('hour', axis=1)
df.head()


for label in df.columns[1:]:
    plt.figure(figsize=(6, 4))
    plt.scatter(df[label], df['bike_count'])
    plt.title(f'{label} vs bike_count')
    plt.xlabel(label)
    plt.ylabel('Bike count at noon')
    plt.tight_layout()
    plt.show()


df = df.drop(['wind', 'visibility', 'functional'], axis=1)
df.head()





train, valid, test = np.split(df.sample(frac=1).reset_index(drop=True), [int(0.6*len(df)), int(0.8*len(df))])


# Function to filter it out:
def get_xy(dataframe, y_label, x_labels=None):
    dataframe = copy.deepcopy(dataframe)
    if x_labels is None:
        X = dataframe[[c for c in dataframe.columns if c!=y_label]].values
    else:
        if len(x_labels) == 1:
            X = dataframe[x_labels[0]].values.reshape(-1, 1)
        else:
            X = dataframe[x_labels].values
    y = dataframe[y_label].values.reshape(-1, 1)
    data = np.hstack((X, y))

    return data, X, y


_, X_train_temp, y_train_temp = get_xy(train, 'bike_count', x_labels=['temp'])
_, X_valid_temp, y_valid_temp = get_xy(valid, 'bike_count', x_labels=['temp'])
_, X_test_temp, y_test_temp = get_xy(test, 'bike_count', x_labels=['temp'])


temp_reg = LinearRegression()
temp_reg.fit(X_train_temp, y_train_temp)


# y = mx + c
# m -> coef_, c -> intercept, score -> R² (R-squared) metric:
# R² = 1 - (Residual Sum of Squares / Total Sum of Squares)
print(temp_reg.coef_, temp_reg.intercept_)
print(temp_reg.score(X_test_temp, y_test_temp))


# Plotting and visualizing
plt.scatter(X_train_temp, y_train_temp, label='Data', color='blue')
x = np.linspace(-20,40,100).reshape(-1,1)
plt.plot(x, temp_reg.predict(x), label='Fit', color='red', linewidth=3)
plt.legend()
plt.xlabel('Temp')
plt.ylabel('No. of bikes')
plt.title('Bikes vs Temp')
plt.show()





train, valid, test = np.split(df.sample(frac=1).reset_index(drop=True), [int(0.6*len(df)), int(0.8*len(df))])
_, X_train_all, y_train_all = get_xy(train, 'bike_count', x_labels=df.columns[1:])
_, X_valid_all, y_valid_all = get_xy(valid, 'bike_count', x_labels=df.columns[1:])
_, X_test_all, y_test_all = get_xy(test, 'bike_count', x_labels=df.columns[1:])


all_reg = LinearRegression()
all_reg.fit(X_train_all, y_train_all)


print(all_reg.score(X_test_all, y_test_all))


y_predict_all = all_reg.predict(X_test_all)





temp_norm = tf.keras.layers.Normalization(input_shape=(1,), axis=None)
temp_norm.adapt(X_train_temp.reshape(-1))


temp_nn_model = tf.keras.Sequential([temp_norm, tf.keras.layers.Dense(1)])


temp_nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1), loss='mse')


history = temp_nn_model.fit(X_train_temp.reshape(-1), y_train_temp, verbose=0, epochs=1000, validation_data=(X_valid_temp, y_valid_temp))


def plot_loss(history):
    plt.plot(history.history['loss'], label='loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.xlabel('Epoch')
    plt.ylabel('MSE')
    plt.legend()
    plt.grid(True)
    plt.show()


plot_loss(history)


# Plotting and visualizing
plt.scatter(X_train_temp, y_train_temp, label='Data', color='blue')
x = np.linspace(-20,40,100).reshape(-1,1)
plt.plot(x, temp_nn_model.predict(x), label='Fit', color='red', linewidth=3)
plt.legend()
plt.xlabel('Temp')
plt.ylabel('No. of bikes')
plt.title('Bikes vs Temp')
plt.show()





nn_model = tf.keras.Sequential([
    temp_norm, 
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='relu'),
])


nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')


history = nn_model.fit(
    X_train_temp, y_train_temp,
    validation_data=(X_valid_temp, y_valid_temp),
    verbose=0, epochs=100
)


plot_loss(history)


# Plotting and visualizing
plt.scatter(X_train_temp, y_train_temp, label='Data', color='blue')
x = np.linspace(-20,40,100).reshape(-1,1)
plt.plot(x, nn_model.predict(x), label='Fit', color='red', linewidth=3)
plt.legend()
plt.xlabel('Temp')
plt.ylabel('No. of bikes')
plt.title('Bikes vs Temp')
plt.show()


all_norm = tf.keras.layers.Normalization(input_shape=(6,), axis=-1)
all_norm.adapt(X_train_all)


nn_model = tf.keras.Sequential([
    all_norm, 
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1),
])
nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')


history = nn_model.fit(
    X_train_all, y_train_all,
    validation_data=(X_valid_all, y_valid_all),
    verbose=0, epochs=100
)


plot_loss(history)


y_predict_all_nn = nn_model.predict(X_test_all)


# MSE
def MSE(y_pred, y_real):
    return np.square(y_pred - y_real).mean()


MSE(y_predict_all, y_test_all)


MSE(y_predict_all_nn, y_test_all)


ax = plt.axes(aspect='equal')
plt.scatter(y_test_all, y_predict_all, label='Lin Reg Pred')
plt.scatter(y_test_all, y_predict_all_nn, label='NN Pred')



